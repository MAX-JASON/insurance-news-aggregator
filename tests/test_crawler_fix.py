"""
æ¸¬è©¦çˆ¬èŸ²ä¿®å¾©å¾Œçš„åŠŸèƒ½
"""

import requests
import json
import time
from datetime import datetime

BASE_URL = "http://localhost:5000"

def test_crawler_api():
    """æ¸¬è©¦çˆ¬èŸ²ç›¸é—œçš„ API"""
    print("ğŸ§ª æ¸¬è©¦çˆ¬èŸ² API...")
    
    # æ¸¬è©¦çˆ¬èŸ²ç‹€æ…‹ç«¯é»
    endpoints = [
        ("/api/v1/crawler/status", "çˆ¬èŸ²ç‹€æ…‹ V1"),
        ("/api/v1/stats", "çµ±è¨ˆè³‡æ–™ V1"),
        ("/api/v1/crawler/sources", "çˆ¬èŸ²ä¾†æº V1"),
    ]
    
    for endpoint, description in endpoints:
        print(f"\nğŸ“¡ æ¸¬è©¦: {description}")
        print(f"ğŸ”— URL: {BASE_URL}{endpoint}")
        
        try:
            response = requests.get(f"{BASE_URL}{endpoint}", timeout=10)
            print(f"ğŸ“Š ç‹€æ…‹ç¢¼: {response.status_code}")
            
            if response.status_code == 200:
                data = response.json()
                print(f"âœ… API å›æ‡‰æˆåŠŸ")
                
                # æª¢æŸ¥æ•¸æ“šçµæ§‹
                if data.get('status') == 'success' and 'data' in data:
                    print(f"ğŸ“¦ åŒ…å«æ•¸æ“šçµæ§‹")
                    
                    # æª¢æŸ¥çˆ¬èŸ²ç‹€æ…‹ç‰¹å®šæ¬„ä½
                    if endpoint == "/api/v1/crawler/status":
                        required_fields = ['source_totals', 'recent_runs', 'total_news', 'today_news']
                        for field in required_fields:
                            if field in data['data']:
                                print(f"âœ… åŒ…å« {field}: {type(data['data'][field])}")
                                if field == 'source_totals' and data['data'][field]:
                                    print(f"   - ç¬¬ä¸€å€‹ä¾†æº: {data['data'][field][0]}")
                            else:
                                print(f"âŒ ç¼ºå°‘ {field}")
                    
                    # æª¢æŸ¥çµ±è¨ˆè³‡æ–™ç‰¹å®šæ¬„ä½
                    elif endpoint == "/api/v1/stats":
                        required_fields = ['totalNews', 'totalSources', 'source_totals']
                        for field in required_fields:
                            if field in data['data']:
                                print(f"âœ… åŒ…å« {field}: {type(data['data'][field])}")
                            else:
                                print(f"âŒ ç¼ºå°‘ {field}")
                
                else:
                    print(f"âš ï¸ å›æ‡‰æ ¼å¼ç•°å¸¸: {list(data.keys())}")
                    
            else:
                print(f"âŒ API éŒ¯èª¤: {response.text[:200]}")
                
        except Exception as e:
            print(f"âŒ è«‹æ±‚å¤±æ•—: {e}")

def test_web_pages():
    """æ¸¬è©¦ç¶²é æ˜¯å¦æ­£å¸¸è¼‰å…¥"""
    print("\nğŸŒ æ¸¬è©¦ç¶²é è¼‰å…¥...")
    
    pages = [
        ("/monitor/crawler", "çˆ¬èŸ²ç›£æ§é é¢"),
        ("/monitor/manual_crawl", "æ‰‹å‹•åŸ·è¡Œçˆ¬èŸ²é é¢"),
        ("/monitor/settings", "ç›£æ§è¨­å®šé é¢"),
        ("/", "é¦–é "),
    ]
    
    for page, description in pages:
        print(f"\nğŸ” æ¸¬è©¦: {description}")
        print(f"ğŸ”— URL: {BASE_URL}{page}")
        
        try:
            response = requests.get(f"{BASE_URL}{page}", timeout=10)
            print(f"ğŸ“Š ç‹€æ…‹ç¢¼: {response.status_code}")
            
            if response.status_code == 200:
                content_length = len(response.text)
                print(f"âœ… é é¢è¼‰å…¥æˆåŠŸï¼Œå…§å®¹é•·åº¦: {content_length}")
                
                # æª¢æŸ¥æ˜¯å¦åŒ…å«é‡è¦çš„ JavaScript æˆ– HTML å…ƒç´ 
                if "bootstrap" in response.text.lower():
                    print("âœ… åŒ…å« Bootstrap æ¡†æ¶")
                if "api/v1" in response.text:
                    print("âœ… åŒ…å« V1 API èª¿ç”¨")
                if "source_totals" in response.text:
                    print("âœ… åŒ…å« source_totals è™•ç†")
                    
            else:
                print(f"âŒ é é¢éŒ¯èª¤: {response.status_code}")
                
        except Exception as e:
            print(f"âŒ è«‹æ±‚å¤±æ•—: {e}")

def test_crawler_start():
    """æ¸¬è©¦çˆ¬èŸ²å•Ÿå‹•åŠŸèƒ½"""
    print("\nğŸš€ æ¸¬è©¦çˆ¬èŸ²å•Ÿå‹•...")
    
    try:
        # ä½¿ç”¨æ¨¡æ“¬æ•¸æ“šå•Ÿå‹•çˆ¬èŸ²
        response = requests.post(
            f"{BASE_URL}/api/v1/crawler/start",
            json={"use_mock": True},
            timeout=30
        )
        
        print(f"ğŸ“Š ç‹€æ…‹ç¢¼: {response.status_code}")
        
        if response.status_code == 200:
            data = response.json()
            print(f"âœ… çˆ¬èŸ²å•Ÿå‹•å›æ‡‰: {data.get('message', 'ç„¡è¨Šæ¯')}")
            
            if data.get('status') == 'success':
                print("ğŸ‰ çˆ¬èŸ²å•Ÿå‹•æˆåŠŸï¼")
            else:
                print(f"âš ï¸ çˆ¬èŸ²å•Ÿå‹•ç‹€æ…‹: {data.get('status')}")
                
        else:
            print(f"âŒ çˆ¬èŸ²å•Ÿå‹•å¤±æ•—: {response.text[:200]}")
            
    except Exception as e:
        print(f"âŒ çˆ¬èŸ²å•Ÿå‹•è«‹æ±‚å¤±æ•—: {e}")

if __name__ == "__main__":
    print("=" * 60)
    print("ğŸ”§ ä¿éšªæ–°èèšåˆå™¨ - çˆ¬èŸ²ä¿®å¾©æ¸¬è©¦")
    print(f"â° æ¸¬è©¦æ™‚é–“: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("=" * 60)
    
    # åŸ·è¡Œæ¸¬è©¦
    test_crawler_api()
    test_web_pages()
    test_crawler_start()
    
    print("\n" + "=" * 60)
    print("ğŸ¯ æ¸¬è©¦å®Œæˆ!")
    print("ğŸ’¡ è«‹æª¢æŸ¥ç€è¦½å™¨ä¸­çš„çˆ¬èŸ²ç›£æ§é é¢æ˜¯å¦æ­£å¸¸é¡¯ç¤ºæ•¸æ“š")
    print("=" * 60)
