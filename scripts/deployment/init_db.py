#!/usr/bin/env python3
"""
è³‡æ–™åº«åˆå§‹åŒ–è…³æœ¬
"""

import sys
import os

# æ·»åŠ å°ˆæ¡ˆè·¯å¾‘
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from app import create_app
from config.settings import Config
from database.models import db, News, NewsSource, NewsCategory, CrawlLog
import sqlite3

def init_database():
    """åˆå§‹åŒ–è³‡æ–™åº«"""
    try:
        print("ğŸ”§ æ­£åœ¨åˆå§‹åŒ–è³‡æ–™åº«...")
        
        # å»ºç«‹Flaskæ‡‰ç”¨
        app = create_app(Config)
        
        with app.app_context():
            # å»ºç«‹æ‰€æœ‰è¡¨æ ¼
            db.create_all()
            print("âœ… æ‰€æœ‰è³‡æ–™è¡¨å·²å»ºç«‹")
            
            # æª¢æŸ¥è¡¨æ ¼æ˜¯å¦å­˜åœ¨
            inspector = db.inspect(db.engine)
            tables = inspector.get_table_names()
            print(f"ğŸ“‹ å»ºç«‹çš„è¡¨æ ¼: {tables}")
            
            # æ’å…¥ä¸€äº›æ¸¬è©¦è³‡æ–™
            create_sample_data()
            
    except Exception as e:
        print(f"âŒ è³‡æ–™åº«åˆå§‹åŒ–å¤±æ•—: {e}")
        return False
    
    return True

def create_sample_data():
    """å»ºç«‹ç¯„ä¾‹è³‡æ–™"""
    try:
        # æª¢æŸ¥æ˜¯å¦å·²æœ‰è³‡æ–™
        if NewsCategory.query.first():
            print("ğŸ“ è³‡æ–™åº«å·²æœ‰è³‡æ–™ï¼Œè·³éç¯„ä¾‹è³‡æ–™å»ºç«‹")
            return
        
        print("ğŸ“ æ­£åœ¨å»ºç«‹ç¯„ä¾‹è³‡æ–™...")
          # å»ºç«‹æ–°èåˆ†é¡
        categories = [
            NewsCategory(name="å£½éšª", description="äººå£½ä¿éšªç›¸é—œæ–°è"),
            NewsCategory(name="ç”¢éšª", description="ç”¢éšªç›¸é—œæ–°è"), 
            NewsCategory(name="å¥åº·éšª", description="å¥åº·ä¿éšªç›¸é—œæ–°è"),
            NewsCategory(name="æ³•è¦", description="ä¿éšªæ³•è¦æ–°è")
        ]
        
        for category in categories:
            db.session.add(category)
        
        # å»ºç«‹æ–°èä¾†æº
        sources = [
            NewsSource(
                name="å·¥å•†æ™‚å ±ä¿éšªç‰ˆ",
                url="https://ctee.com.tw/category/insurance",
                description="å·¥å•†æ™‚å ±ä¿éšªæ–°è",
                status="active"
            ),
            NewsSource(
                name="ç¶“æ¿Ÿæ—¥å ±ä¿éšª",  
                url="https://money.udn.com/money/cate/5636",
                description="ç¶“æ¿Ÿæ—¥å ±ä¿éšªæ–°è",
                status="active"
            )
        ]
        
        for source in sources:
            db.session.add(source)
        
        db.session.commit()
          # å»ºç«‹ç¯„ä¾‹æ–°è
        from datetime import datetime, timezone
        now = datetime.now(timezone.utc)
        
        sample_news = [
            News(
                title="å°ç£ä¿éšªæ¥­æ•¸ä½è½‰å‹æ–°è¶¨å‹¢",
                content="éš¨è‘—ç§‘æŠ€ç™¼å±•ï¼Œå°ç£ä¿éšªæ¥­æ­£ç©æ¥µæŠ•å…¥æ•¸ä½è½‰å‹ï¼Œé€éäººå·¥æ™ºæ…§å’Œå¤§æ•¸æ“šåˆ†æï¼Œæä¾›æ›´ç²¾æº–çš„ä¿éšªæœå‹™...",
                summary="ä¿éšªæ¥­é€éAIå’Œå¤§æ•¸æ“šæ¨å‹•æ•¸ä½è½‰å‹ï¼Œæå‡æœå‹™å“è³ª",
                url="https://example.com/news/1",
                source_id=1,
                category_id=1,
                published_date=now,
                crawled_date=now,
                status="active",
                keywords="æ•¸ä½è½‰å‹,äººå·¥æ™ºæ…§,å¤§æ•¸æ“š",
                importance_score=0.8
            ),
            News(
                title="é‡‘ç®¡æœƒç™¼å¸ƒæ–°ç‰ˆä¿éšªæ³•è¦",
                content="é‡‘èç›£ç£ç®¡ç†å§”å“¡æœƒä»Šæ—¥ç™¼å¸ƒæ–°ç‰ˆä¿éšªç›¸é—œæ³•è¦ï¼Œé‡å°æ•¸ä½ä¿éšªæœå‹™æå‡ºæ›´æ˜ç¢ºçš„è¦ç¯„...",
                summary="é‡‘ç®¡æœƒç™¼å¸ƒæ–°ä¿éšªæ³•è¦ï¼Œè¦ç¯„æ•¸ä½ä¿éšªæœå‹™",
                url="https://example.com/news/2", 
                source_id=2,
                category_id=4,
                published_date=now,
                crawled_date=now,
                status="active",
                keywords="é‡‘ç®¡æœƒ,æ³•è¦,æ•¸ä½ä¿éšª",
                importance_score=0.9
            ),
            News(
                title="å¥åº·éšªå¸‚å ´æˆé•·å‰µæ–°é«˜",
                content="å—åˆ°ç–«æƒ…å½±éŸ¿ï¼Œæ°‘çœ¾å°å¥åº·ä¿éšœéœ€æ±‚å¤§å¹…æå‡ï¼Œå¥åº·éšªå¸‚å ´å‘ˆç¾å¼·å‹æˆé•·æ…‹å‹¢...",
                summary="ç–«æƒ…æ¨å‹•å¥åº·éšªéœ€æ±‚ï¼Œå¸‚å ´æˆé•·å‰µæ–°é«˜",
                url="https://example.com/news/3",
                source_id=1, 
                category_id=3,
                published_date=now,
                crawled_date=now,
                status="active",
                keywords="å¥åº·éšª,å¸‚å ´æˆé•·,ç–«æƒ…",
                importance_score=0.7
            )
        ]
        
        for news in sample_news:
            db.session.add(news)
        
        db.session.commit()
        print(f"âœ… å·²å»ºç«‹ {len(categories)} å€‹åˆ†é¡ã€{len(sources)} å€‹ä¾†æºã€{len(sample_news)} å‰‡ç¯„ä¾‹æ–°è")
        
    except Exception as e:
        print(f"âŒ å»ºç«‹ç¯„ä¾‹è³‡æ–™å¤±æ•—: {e}")
        db.session.rollback()

if __name__ == "__main__":
    init_database()
