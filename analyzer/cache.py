"""
åˆ†æçµæœå¿«å–ç³»çµ±
Analysis Result Cache System

æä¾›æ–°èåˆ†æçµæœçš„å¿«å–åŠŸèƒ½ï¼Œæå‡ç³»çµ±æ•ˆèƒ½
"""

import json
import hashlib
import logging
from datetime import datetime, timedelta
from typing import Dict, Any, Optional, List
from functools import wraps
import pickle
import os
from pathlib import Path

logger = logging.getLogger('analyzer.cache')

class AnalysisCache:
    """åˆ†æçµæœå¿«å–ç®¡ç†å™¨"""
    
    def __init__(self, cache_dir: str = "cache", ttl_hours: int = 24, memory_cache_size: int = 500):
        """
        åˆå§‹åŒ–å¿«å–ç³»çµ±
        
        Args:
            cache_dir: å¿«å–æª”æ¡ˆç›®éŒ„
            ttl_hours: å¿«å–ç”Ÿå­˜æ™‚é–“ï¼ˆå°æ™‚ï¼‰
            memory_cache_size: è¨˜æ†¶é«”å¿«å–å¤§å°ï¼ˆé …ç›®æ•¸ï¼‰
        """
        # æª”æ¡ˆå¿«å–è¨­å®š
        self.cache_dir = Path(cache_dir)
        self.cache_dir.mkdir(exist_ok=True)
        self.ttl = timedelta(hours=ttl_hours)
        
        # è¨˜æ†¶é«”å¿«å–è¨­å®š
        self.memory_cache_size = memory_cache_size
        self.memory_cache = {}  # æ ¼å¼: {(category, key): (data, timestamp)}
        self.memory_cache_hits = 0
        self.memory_cache_misses = 0
        self.file_cache_hits = 0
        self.file_cache_misses = 0
        
        # å»ºç«‹å­ç›®éŒ„
        for category in ['analysis', 'importance', 'keywords', 'sentiment', 'trends', 'recommendations']:
            (self.cache_dir / category).mkdir(exist_ok=True)
        
        logger.info(f"âœ… åˆ†æå¿«å–ç³»çµ±åˆå§‹åŒ–å®Œæˆï¼Œç›®éŒ„: {self.cache_dir}ï¼Œè¨˜æ†¶é«”å¿«å–å¤§å°: {memory_cache_size}")
    
    def _get_cache_key(self, data: Any) -> str:
        """
        ç”¢ç”Ÿå¿«å–éµå€¼
        
        Args:
            data: è¦å¿«å–çš„æ•¸æ“š
            
        Returns:
            MD5 é›œæ¹Šéµå€¼
        """
        # é è™•ç†åŒ…å«datetimeçš„æ•¸æ“š
        data = self._preprocess_for_json(data)
        
        if isinstance(data, dict):
            # å°å­—å…¸æ’åºå¾Œåºåˆ—åŒ–
            sorted_data = json.dumps(data, sort_keys=True, ensure_ascii=False)
        elif isinstance(data, str):
            sorted_data = data
        else:
            sorted_data = str(data)
        
        return hashlib.md5(sorted_data.encode('utf-8')).hexdigest()
        
    def _preprocess_for_json(self, data: Any) -> Any:
        """è™•ç†åŒ…å«datetimeçš„æ•¸æ“šä»¥ä¾¿JSONåºåˆ—åŒ–"""
        from datetime import datetime
        
        if isinstance(data, datetime):
            # å°‡datetimeè½‰æ›ç‚ºISOæ ¼å¼å­—ç¬¦ä¸²
            return data.isoformat()
        elif isinstance(data, dict):
            # éæ­¸è™•ç†å­—å…¸
            return {k: self._preprocess_for_json(v) for k, v in data.items()}
        elif isinstance(data, list):
            # éæ­¸è™•ç†åˆ—è¡¨
            return [self._preprocess_for_json(item) for item in data]
        elif isinstance(data, tuple):
            # è™•ç†å…ƒçµ„
            return tuple(self._preprocess_for_json(item) for item in data)
        else:
            # å…¶ä»–é¡å‹ç›´æ¥è¿”å›
            return data
    
    def _get_cache_path(self, category: str, key: str) -> Path:
        """å–å¾—å¿«å–æª”æ¡ˆè·¯å¾‘"""
        return self.cache_dir / category / f"{key}.cache"
    
    def _is_cache_valid(self, cache_path: Path) -> bool:
        """æª¢æŸ¥å¿«å–æ˜¯å¦ä»ç„¶æœ‰æ•ˆ"""
        if not cache_path.exists():
            return False
        
        # æª¢æŸ¥æª”æ¡ˆä¿®æ”¹æ™‚é–“
        file_time = datetime.fromtimestamp(cache_path.stat().st_mtime)
        return datetime.now() - file_time < self.ttl
    
    def get(self, category: str, key: str) -> Optional[Dict[str, Any]]:
        """
        å¾å¿«å–ä¸­å–å¾—è³‡æ–™
        
        Args:
            category: å¿«å–åˆ†é¡ (analysis, keywords, sentiment, trends)
            key: å¿«å–éµå€¼
            
        Returns:
            å¿«å–çš„è³‡æ–™ï¼Œå¦‚æœä¸å­˜åœ¨æˆ–éæœŸå‰‡è¿”å› None
        """
        try:
            # 1. å…ˆæª¢æŸ¥è¨˜æ†¶é«”å¿«å–
            cache_key = (category, key)
            if cache_key in self.memory_cache:
                data, timestamp = self.memory_cache[cache_key]
                if datetime.now() - timestamp < self.ttl:
                    self.memory_cache_hits += 1
                    logger.debug(f"âœ… è¨˜æ†¶é«”å¿«å–å‘½ä¸­: {category}/{key}")
                    return data
                else:
                    # éæœŸé …ç›®å¾è¨˜æ†¶é«”ä¸­ç§»é™¤
                    del self.memory_cache[cache_key]
            
            self.memory_cache_misses += 1
            
            # 2. æª¢æŸ¥æª”æ¡ˆå¿«å–
            cache_path = self._get_cache_path(category, key)
            
            if not self._is_cache_valid(cache_path):
                self.file_cache_misses += 1
                return None
            
            with open(cache_path, 'rb') as f:
                cached_data = pickle.load(f)
            
            # åŠ å…¥è¨˜æ†¶é«”å¿«å–
            self._add_to_memory_cache(category, key, cached_data)
            
            self.file_cache_hits += 1
            logger.debug(f"âœ… æª”æ¡ˆå¿«å–å‘½ä¸­: {category}/{key}")
            return cached_data
            
        except Exception as e:
            logger.debug(f"âŒ è®€å–å¿«å–å¤±æ•—: {category}/{key} - {e}")
            return None
    
    def _add_to_memory_cache(self, category: str, key: str, data: Dict[str, Any]) -> None:
        """å°‡è³‡æ–™åŠ å…¥è¨˜æ†¶é«”å¿«å–"""
        cache_key = (category, key)
        
        # å¦‚æœè¨˜æ†¶é«”å¿«å–å·²æ»¿ï¼Œç§»é™¤æœ€èˆŠçš„é …ç›®
        if len(self.memory_cache) >= self.memory_cache_size:
            # ç°¡å–®çš„ LRU ç­–ç•¥ï¼šç§»é™¤ç¬¬ä¸€å€‹é …ç›®
            oldest_key = next(iter(self.memory_cache))
            del self.memory_cache[oldest_key]
        
        # åŠ å…¥æ–°é …ç›®
        self.memory_cache[cache_key] = (data, datetime.now())
    
    def set(self, category: str, key: str, data: Dict[str, Any]) -> bool:
        """
        å°‡è³‡æ–™å­˜å…¥å¿«å–
        
        Args:
            category: å¿«å–åˆ†é¡
            key: å¿«å–éµå€¼
            data: è¦å¿«å–çš„è³‡æ–™
            
        Returns:
            æ˜¯å¦æˆåŠŸå­˜å…¥
        """
        try:
            # 1. å­˜å…¥è¨˜æ†¶é«”å¿«å–
            self._add_to_memory_cache(category, key, data)
            
            # 2. å­˜å…¥æª”æ¡ˆå¿«å–
            cache_path = self._get_cache_path(category, key)
            
            with open(cache_path, 'wb') as f:
                pickle.dump(data, f)
            
            logger.debug(f"âœ… è³‡æ–™å·²å¿«å–: {category}/{key}")
            return True
            
        except Exception as e:
            logger.error(f"âŒ å¿«å–å¯«å…¥å¤±æ•—: {category}/{key} - {e}")
            return False
    
    def delete(self, category: str, key: str) -> bool:
        """
        åˆªé™¤ç‰¹å®šå¿«å–
        
        Args:
            category: å¿«å–åˆ†é¡
            key: å¿«å–éµå€¼
            
        Returns:
            æ˜¯å¦æˆåŠŸåˆªé™¤
        """
        try:
            # 1. å¾è¨˜æ†¶é«”å¿«å–ä¸­åˆªé™¤
            cache_key = (category, key)
            if cache_key in self.memory_cache:
                del self.memory_cache[cache_key]
            
            # 2. å¾æª”æ¡ˆå¿«å–ä¸­åˆªé™¤
            cache_path = self._get_cache_path(category, key)
            if cache_path.exists():
                cache_path.unlink()
                logger.debug(f"âœ… å¿«å–å·²åˆªé™¤: {category}/{key}")
                return True
            return False
            
        except Exception as e:
            logger.error(f"âŒ å¿«å–åˆªé™¤å¤±æ•—: {category}/{key} - {e}")
            return False
    
    def clear_category(self, category: str) -> int:
        """
        æ¸…ç©ºç‰¹å®šåˆ†é¡çš„æ‰€æœ‰å¿«å–
        
        Args:
            category: å¿«å–åˆ†é¡
            
        Returns:
            åˆªé™¤çš„æª”æ¡ˆæ•¸é‡
        """
        try:
            # 1. æ¸…ç©ºè¨˜æ†¶é«”å¿«å–ä¸­çš„è©²åˆ†é¡é …ç›®
            keys_to_remove = [k for k in self.memory_cache.keys() if k[0] == category]
            for key in keys_to_remove:
                del self.memory_cache[key]
            
            # 2. æ¸…ç©ºæª”æ¡ˆå¿«å–
            category_dir = self.cache_dir / category
            if not category_dir.exists():
                return 0
            
            count = 0
            for cache_file in category_dir.glob("*.cache"):
                cache_file.unlink()
                count += 1
            
            logger.info(f"âœ… å·²æ¸…ç©º {category} å¿«å–ï¼Œåˆªé™¤ {count} å€‹æª”æ¡ˆ")
            return count
            
        except Exception as e:
            logger.error(f"âŒ æ¸…ç©ºå¿«å–å¤±æ•—: {category} - {e}")
            return 0
    
    def clear_expired(self) -> int:
        """
        æ¸…ç†éæœŸçš„å¿«å–
        
        Returns:
            åˆªé™¤çš„æª”æ¡ˆæ•¸é‡
        """
        try:
            # 1. æ¸…ç†è¨˜æ†¶é«”å¿«å–
            now = datetime.now()
            keys_to_remove = []
            for k, (_, timestamp) in self.memory_cache.items():
                if now - timestamp >= self.ttl:
                    keys_to_remove.append(k)
            
            for key in keys_to_remove:
                del self.memory_cache[key]
            
            memory_count = len(keys_to_remove)
            logger.debug(f"âœ… å·²æ¸…ç† {memory_count} å€‹éæœŸè¨˜æ†¶é«”å¿«å–é …ç›®")
            
            # 2. æ¸…ç†æª”æ¡ˆå¿«å–
            file_count = 0
            for cache_file in self.cache_dir.rglob("*.cache"):
                if not self._is_cache_valid(cache_file):
                    cache_file.unlink()
                    file_count += 1
            
            logger.info(f"âœ… å·²æ¸…ç† {memory_count} å€‹è¨˜æ†¶é«”å¿«å–é …ç›®å’Œ {file_count} å€‹éæœŸå¿«å–æª”æ¡ˆ")
            return file_count + memory_count
            
        except Exception as e:
            logger.error(f"âŒ æ¸…ç†éæœŸå¿«å–å¤±æ•—: {e}")
            return 0
    
    def get_cache_stats(self) -> Dict[str, Any]:
        """
        å–å¾—å¿«å–çµ±è¨ˆè³‡è¨Š
        
        Returns:
            å¿«å–çµ±è¨ˆè³‡æ–™
        """
        try:
            now = datetime.now()
            stats = {
                'categories': {},
                'total_files': 0,
                'total_size': 0,
                'expired_files': 0,
                'memory_cache': {
                    'total_items': len(self.memory_cache),
                    'max_size': self.memory_cache_size,
                    'usage_percent': len(self.memory_cache) / self.memory_cache_size * 100 if self.memory_cache_size > 0 else 0,
                    'hits': self.memory_cache_hits,
                    'misses': self.memory_cache_misses,
                    'hit_ratio': self.memory_cache_hits / (self.memory_cache_hits + self.memory_cache_misses) * 100 if (self.memory_cache_hits + self.memory_cache_misses) > 0 else 0,
                    'categories': {}
                },
                'file_cache': {
                    'hits': self.file_cache_hits,
                    'misses': self.file_cache_misses,
                    'hit_ratio': self.file_cache_hits / (self.file_cache_hits + self.file_cache_misses) * 100 if (self.file_cache_hits + self.file_cache_misses) > 0 else 0
                }
            }
            
            # è¨˜æ†¶é«”å¿«å–çµ±è¨ˆ
            memory_categories = {}
            valid_memory_items = 0
            expired_memory_items = 0
            
            for (cat, _), (_, timestamp) in self.memory_cache.items():
                if cat not in memory_categories:
                    memory_categories[cat] = {'count': 0, 'expired': 0}
                
                memory_categories[cat]['count'] += 1
                
                if now - timestamp >= self.ttl:
                    memory_categories[cat]['expired'] += 1
                    expired_memory_items += 1
                else:
                    valid_memory_items += 1
            
            stats['memory_cache']['categories'] = memory_categories
            stats['memory_cache']['valid_items'] = valid_memory_items
            stats['memory_cache']['expired_items'] = expired_memory_items
            
            # æª”æ¡ˆå¿«å–çµ±è¨ˆ
            for category_dir in self.cache_dir.iterdir():
                if category_dir.is_dir():
                    category_name = category_dir.name
                    cache_files = list(category_dir.glob("*.cache"))
                    
                    valid_files = 0
                    expired_files = 0
                    category_size = 0
                    
                    for cache_file in cache_files:
                        file_size = cache_file.stat().st_size
                        category_size += file_size
                        
                        if self._is_cache_valid(cache_file):
                            valid_files += 1
                        else:
                            expired_files += 1
                    
                    stats['categories'][category_name] = {
                        'valid_files': valid_files,
                        'expired_files': expired_files,
                        'total_files': len(cache_files),
                        'size_bytes': category_size,
                        'memory_items': memory_categories.get(category_name, {}).get('count', 0)
                    }
                    
                    stats['total_files'] += len(cache_files)
                    stats['total_size'] += category_size
                    stats['expired_files'] += expired_files
            
            # è¨ˆç®—æ•´é«”æ•ˆèƒ½
            total_hits = self.memory_cache_hits + self.file_cache_hits
            total_requests = total_hits + self.file_cache_misses
            
            stats['overall_hit_ratio'] = total_hits / total_requests * 100 if total_requests > 0 else 0
            stats['overall_performance'] = {
                'total_hits': total_hits,
                'total_misses': self.file_cache_misses,
                'total_requests': total_requests
            }
            
            return stats
            
        except Exception as e:
            logger.error(f"âŒ å–å¾—å¿«å–çµ±è¨ˆå¤±æ•—: {e}")
            return {}

# å…¨åŸŸå¿«å–å¯¦ä¾‹
_cache_instance = None

def get_cache() -> AnalysisCache:
    """å–å¾—å…¨åŸŸå¿«å–å¯¦ä¾‹"""
    global _cache_instance
    if _cache_instance is None:
        _cache_instance = AnalysisCache()
    return _cache_instance

def cached_analysis(category: str = 'analysis', ttl_hours: int = None, skip_args: List[int] = None, skip_kwargs: List[str] = None):
    """
    åˆ†æçµæœå¿«å–è£é£¾å™¨
    
    Args:
        category: å¿«å–åˆ†é¡
        ttl_hours: è¦†å¯«é è¨­çš„å¿«å–ç”Ÿå­˜æ™‚é–“ï¼ˆå°æ™‚ï¼‰
        skip_args: è¦æ’é™¤åœ¨å¿«å–éµå€¼è¨ˆç®—å¤–çš„ä½ç½®åƒæ•¸ç´¢å¼•åˆ—è¡¨
        skip_kwargs: è¦æ’é™¤åœ¨å¿«å–éµå€¼è¨ˆç®—å¤–çš„é—œéµå­—åƒæ•¸åç¨±åˆ—è¡¨
    """
    def decorator(func):
        @wraps(func)
        def wrapper(*args, **kwargs):
            cache = get_cache()
            
            # ç”¢ç”Ÿå¿«å–éµå€¼ (æ’é™¤æŒ‡å®šçš„åƒæ•¸)
            filtered_args = []
            
            # ç‰¹æ®Šè™•ç†ç¬¬ä¸€å€‹åƒæ•¸ï¼ˆé€šå¸¸æ˜¯ selfï¼‰ï¼Œä¸åŒ…å«åœ¨å¿«å–éµå€¼è¨ˆç®—ä¸­
            if len(args) > 0:
                filtered_args = list(args[1:])  # è·³éç¬¬ä¸€å€‹åƒæ•¸ï¼ˆselfï¼‰
            
            if skip_args:
                for i in sorted(skip_args, reverse=True):
                    if i < len(filtered_args):
                        filtered_args[i] = '_SKIPPED_'
            
            filtered_kwargs = kwargs.copy()
            if skip_kwargs:
                for k in skip_kwargs:
                    if k in filtered_kwargs:
                        filtered_kwargs[k] = '_SKIPPED_'
            
            cache_data = {
                'func_name': func.__name__,
                'args': filtered_args,
                'kwargs': filtered_kwargs
            }
            cache_key = cache._get_cache_key(cache_data)
            
            # å˜—è©¦å¾å¿«å–å–å¾—çµæœ
            cached_result = cache.get(category, cache_key)
            if cached_result is not None:
                logger.debug(f"âœ… ä½¿ç”¨å¿«å–çµæœ: {func.__name__}")
                return cached_result
            
            # åŸ·è¡Œå‡½æ•¸ä¸¦å¿«å–çµæœ
            result = func(*args, **kwargs)
            cache.set(category, cache_key, result)
            logger.debug(f"âœ… æ–°å¢å¿«å–çµæœ: {func.__name__}")
            
            return result
        
        return wrapper
    return decorator

def invalidate_cache(category: str = None, pattern: str = None):
    """
    ç„¡æ•ˆåŒ–å¿«å–çš„è£é£¾å™¨
    
    Args:
        category: è¦æ¸…ç©ºçš„å¿«å–åˆ†é¡ï¼Œå¦‚æœç‚º None å‰‡ä¸æ¸…ç©ºä»»ä½•åˆ†é¡
        pattern: åŒ¹é…è¦åˆªé™¤çš„å¿«å–éµå€¼æ¨¡å¼ï¼Œå¦‚æœç‚º None å‰‡åˆªé™¤æ•´å€‹åˆ†é¡
    """
    def decorator(func):
        @wraps(func)
        def wrapper(*args, **kwargs):
            cache = get_cache()
            
            # åŸ·è¡Œå‡½æ•¸
            result = func(*args, **kwargs)
            
            # ç„¡æ•ˆåŒ–å¿«å–
            if category:
                if pattern:
                    # å°‹æ‰¾åŒ¹é…çš„éµå€¼åˆªé™¤
                    keys_to_delete = []
                    category_path = cache.cache_dir / category
                    if category_path.exists():
                        for cache_file in category_path.glob("*.cache"):
                            if pattern in cache_file.name:
                                keys_to_delete.append(cache_file.stem)
                    
                    for key in keys_to_delete:
                        cache.delete(category, key)
                        
                    logger.debug(f"âœ… å·²ç„¡æ•ˆåŒ– {len(keys_to_delete)} å€‹å¿«å–é …ç›®: {category}/{pattern}")
                else:
                    # æ¸…ç©ºæ•´å€‹åˆ†é¡
                    count = cache.clear_category(category)
                    logger.debug(f"âœ… å·²ç„¡æ•ˆåŒ–åˆ†é¡ {category}ï¼Œæ¸…é™¤ {count} å€‹é …ç›®")
            
            return result
            
        return wrapper
    return decorator

if __name__ == "__main__":
    # æ¸¬è©¦å¿«å–ç³»çµ±
    print("ğŸ§ª æ¸¬è©¦åˆ†æçµæœå¿«å–ç³»çµ±...")
    
    cache = AnalysisCache(cache_dir="test_cache", ttl_hours=1)
    
    # æ¸¬è©¦åŸºæœ¬æ“ä½œ
    test_data = {
        'sentiment': 'positive',
        'score': 0.8,
        'keywords': ['ä¿éšª', 'ç†è³ ', 'æœå‹™']
    }
    
    # å­˜å…¥å¿«å–
    cache.set('analysis', 'test_key', test_data)
    
    # å¾å¿«å–è®€å–
    cached_data = cache.get('analysis', 'test_key')
    print(f"å¿«å–æ¸¬è©¦çµæœ: {cached_data}")
    
    # å–å¾—çµ±è¨ˆ
    stats = cache.get_cache_stats()
    print(f"å¿«å–çµ±è¨ˆ: {stats}")
    
    # æ¸…ç†æ¸¬è©¦å¿«å–
    import shutil
    shutil.rmtree("test_cache")
    print("âœ… å¿«å–ç³»çµ±æ¸¬è©¦å®Œæˆ")
